{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T00:14:53.459391Z",
     "start_time": "2018-01-25T00:14:49.487330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import keras\n",
    "from keras import backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T01:58:38.596123Z",
     "start_time": "2018-01-25T01:58:35.182021Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "x_train = (x_train - np.mean(x_train, axis = (1,2), keepdims=True))/np.std(x_train, axis = (1,2), keepdims=True)\n",
    "x_test = (x_test - np.mean(x_test, axis = (1,2), keepdims=True))/np.std(x_test, axis = (1,2), keepdims=True)\n",
    "x_train = x_train.reshape((-1,28,28,1))\n",
    "x_test = x_test.reshape((-1,28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T02:12:29.647118Z",
     "start_time": "2018-01-25T02:12:29.624067Z"
    }
   },
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ReduceLROnPlateau(factor=0.1, patience=1, verbose=1),\n",
    "    keras.callbacks.EarlyStopping(patience=4)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T00:11:47.584139Z",
     "start_time": "2018-01-25T00:08:56.017164Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_13 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_25 (Dense)             (None, 20)                15700     \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_26 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 15,990\n",
      "Trainable params: 15,950\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 9s 198us/step - loss: 0.3502 - sparse_categorical_accuracy: 0.8986 - val_loss: 0.2209 - val_sparse_categorical_accuracy: 0.9347\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 8s 176us/step - loss: 0.2160 - sparse_categorical_accuracy: 0.9353 - val_loss: 0.1996 - val_sparse_categorical_accuracy: 0.9406\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 9s 189us/step - loss: 0.1853 - sparse_categorical_accuracy: 0.9444 - val_loss: 0.1827 - val_sparse_categorical_accuracy: 0.9458\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 8s 162us/step - loss: 0.1655 - sparse_categorical_accuracy: 0.9481 - val_loss: 0.1629 - val_sparse_categorical_accuracy: 0.9517\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 8s 167us/step - loss: 0.1549 - sparse_categorical_accuracy: 0.9526 - val_loss: 0.1584 - val_sparse_categorical_accuracy: 0.9544\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 9s 188us/step - loss: 0.1476 - sparse_categorical_accuracy: 0.9531 - val_loss: 0.1525 - val_sparse_categorical_accuracy: 0.9529\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 10s 200us/step - loss: 0.1398 - sparse_categorical_accuracy: 0.9563 - val_loss: 0.1435 - val_sparse_categorical_accuracy: 0.9578\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 9s 198us/step - loss: 0.1374 - sparse_categorical_accuracy: 0.9577 - val_loss: 0.1423 - val_sparse_categorical_accuracy: 0.9581\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 9s 185us/step - loss: 0.1299 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.1478 - val_sparse_categorical_accuracy: 0.9561\n",
      "Epoch 10/100\n",
      "47808/48000 [============================>.] - ETA: 0s - loss: 0.1254 - sparse_categorical_accuracy: 0.9612\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "48000/48000 [==============================] - 9s 181us/step - loss: 0.1257 - sparse_categorical_accuracy: 0.9612 - val_loss: 0.1494 - val_sparse_categorical_accuracy: 0.9557\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 9s 189us/step - loss: 0.1045 - sparse_categorical_accuracy: 0.9677 - val_loss: 0.1253 - val_sparse_categorical_accuracy: 0.9645\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 9s 180us/step - loss: 0.0994 - sparse_categorical_accuracy: 0.9689 - val_loss: 0.1228 - val_sparse_categorical_accuracy: 0.9651\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 8s 170us/step - loss: 0.0977 - sparse_categorical_accuracy: 0.9698 - val_loss: 0.1233 - val_sparse_categorical_accuracy: 0.9655\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 9s 189us/step - loss: 0.0953 - sparse_categorical_accuracy: 0.9709 - val_loss: 0.1224 - val_sparse_categorical_accuracy: 0.9648\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 7s 151us/step - loss: 0.0935 - sparse_categorical_accuracy: 0.9707 - val_loss: 0.1235 - val_sparse_categorical_accuracy: 0.9652\n",
      "Epoch 16/100\n",
      "47776/48000 [============================>.] - ETA: 0s - loss: 0.0928 - sparse_categorical_accuracy: 0.9714- ETA: 1s - loss: 0.0901 - spar\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "48000/48000 [==============================] - 8s 160us/step - loss: 0.0926 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.1242 - val_sparse_categorical_accuracy: 0.9645\n",
      "Epoch 17/100\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.0912 - sparse_categorical_accuracy: 0.9721- ETA: 3s -\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
      "48000/48000 [==============================] - 8s 163us/step - loss: 0.0912 - sparse_categorical_accuracy: 0.9720 - val_loss: 0.1227 - val_sparse_categorical_accuracy: 0.9656\n",
      "Epoch 18/100\n",
      "47776/48000 [============================>.] - ETA: 0s - loss: 0.0913 - sparse_categorical_accuracy: 0.9716\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 2.000000222324161e-07.\n",
      "48000/48000 [==============================] - 9s 183us/step - loss: 0.0913 - sparse_categorical_accuracy: 0.9715 - val_loss: 0.1229 - val_sparse_categorical_accuracy: 0.9652\n",
      "Epoch 19/100\n",
      "47616/48000 [============================>.] - ETA: 0s - loss: 0.0917 - sparse_categorical_accuracy: 0.9712\n",
      "Epoch 00019: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-08.\n",
      "48000/48000 [==============================] - 7s 140us/step - loss: 0.0916 - sparse_categorical_accuracy: 0.9712 - val_loss: 0.1227 - val_sparse_categorical_accuracy: 0.9656\n",
      "Epoch 20/100\n",
      "47648/48000 [============================>.] - ETA: 0s - loss: 0.0911 - sparse_categorical_accuracy: 0.9714\n",
      "Epoch 00020: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-09.\n",
      "48000/48000 [==============================] - 8s 161us/step - loss: 0.0911 - sparse_categorical_accuracy: 0.9714 - val_loss: 0.1230 - val_sparse_categorical_accuracy: 0.9650\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x120b4a9b0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(20, activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(np.max(y_train) + 1, activation=\"softmax\")\n",
    "])\n",
    "fc_model.summary()\n",
    "fc_model.compile(\n",
    "    \"nadam\",\n",
    "    \"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"])\n",
    "fc_model.fit(\n",
    "    x=x_train, y=y_train, validation_split=.2, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T02:12:29.059643Z",
     "start_time": "2018-01-25T01:58:41.473504Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 26, 26, 10)        100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 12, 12, 10)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 12, 12, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 10, 10, 10)        910       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 10)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 4, 4, 10)          40        \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 160)               0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 20)                3220      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 4,600\n",
      "Trainable params: 4,520\n",
      "Non-trainable params: 80\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 50s 1ms/step - loss: 0.2070 - sparse_categorical_accuracy: 0.9421 - val_loss: 0.0763 - val_sparse_categorical_accuracy: 0.9778\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 47s 973us/step - loss: 0.0766 - sparse_categorical_accuracy: 0.9761 - val_loss: 0.0583 - val_sparse_categorical_accuracy: 0.9824\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 43s 900us/step - loss: 0.0628 - sparse_categorical_accuracy: 0.9809 - val_loss: 0.0640 - val_sparse_categorical_accuracy: 0.9795\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.0541 - sparse_categorical_accuracy: 0.9832 - val_loss: 0.0477 - val_sparse_categorical_accuracy: 0.9855\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 45s 941us/step - loss: 0.0496 - sparse_categorical_accuracy: 0.9848 - val_loss: 0.0478 - val_sparse_categorical_accuracy: 0.9852\n",
      "Epoch 6/100\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.0441 - sparse_categorical_accuracy: 0.9860\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.0441 - sparse_categorical_accuracy: 0.9860 - val_loss: 0.0564 - val_sparse_categorical_accuracy: 0.9848\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 56s 1ms/step - loss: 0.0321 - sparse_categorical_accuracy: 0.9897 - val_loss: 0.0383 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 49s 1ms/step - loss: 0.0284 - sparse_categorical_accuracy: 0.9910 - val_loss: 0.0387 - val_sparse_categorical_accuracy: 0.9900\n",
      "Epoch 9/100\n",
      "47968/48000 [============================>.] - ETA: 0s - loss: 0.0261 - sparse_categorical_accuracy: 0.9921\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "48000/48000 [==============================] - 39s 802us/step - loss: 0.0261 - sparse_categorical_accuracy: 0.9921 - val_loss: 0.0387 - val_sparse_categorical_accuracy: 0.9894\n",
      "Epoch 10/100\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.0253 - sparse_categorical_accuracy: 0.9921\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
      "48000/48000 [==============================] - 51s 1ms/step - loss: 0.0253 - sparse_categorical_accuracy: 0.9921 - val_loss: 0.0382 - val_sparse_categorical_accuracy: 0.9899\n",
      "Epoch 11/100\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.0242 - sparse_categorical_accuracy: 0.9924\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 2.000000222324161e-07.\n",
      "48000/48000 [==============================] - 58s 1ms/step - loss: 0.0242 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0386 - val_sparse_categorical_accuracy: 0.9900\n",
      "Epoch 12/100\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.0244 - sparse_categorical_accuracy: 0.9928\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-08.\n",
      "48000/48000 [==============================] - 54s 1ms/step - loss: 0.0245 - sparse_categorical_accuracy: 0.9927 - val_loss: 0.0384 - val_sparse_categorical_accuracy: 0.9899\n",
      "Epoch 13/100\n",
      "47968/48000 [============================>.] - ETA: 0s - loss: 0.0241 - sparse_categorical_accuracy: 0.9925\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-09.\n",
      "48000/48000 [==============================] - 54s 1ms/step - loss: 0.0241 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0384 - val_sparse_categorical_accuracy: 0.9898\n",
      "Epoch 14/100\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.0245 - sparse_categorical_accuracy: 0.9924\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-10.\n",
      "48000/48000 [==============================] - 57s 1ms/step - loss: 0.0244 - sparse_categorical_accuracy: 0.9924 - val_loss: 0.0383 - val_sparse_categorical_accuracy: 0.9899\n",
      "Epoch 15/100\n",
      "47968/48000 [============================>.] - ETA: 0s - loss: 0.0244 - sparse_categorical_accuracy: 0.9925\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-11.\n",
      "48000/48000 [==============================] - 58s 1ms/step - loss: 0.0244 - sparse_categorical_accuracy: 0.9925 - val_loss: 0.0387 - val_sparse_categorical_accuracy: 0.9899\n",
      "Epoch 16/100\n",
      "47968/48000 [============================>.] - ETA: 0s - loss: 0.0249 - sparse_categorical_accuracy: 0.9923\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-12.\n",
      "48000/48000 [==============================] - 49s 1ms/step - loss: 0.0249 - sparse_categorical_accuracy: 0.9923 - val_loss: 0.0383 - val_sparse_categorical_accuracy: 0.9900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x123d21ef0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Conv2D(10,3,activation=\"elu\"),\n",
    "    keras.layers.MaxPool2D(3,2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(10,3,activation=\"elu\"),\n",
    "    keras.layers.MaxPool2D(3,2),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(20, activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(np.max(y_train) + 1, activation=\"softmax\")\n",
    "])\n",
    "fc_model.summary()\n",
    "fc_model.compile(\n",
    "    \"nadam\",\n",
    "    \"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"])\n",
    "fc_model.fit(\n",
    "    x=x_train, y=y_train, validation_split=.2, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T02:13:18.233017Z",
     "start_time": "2018-01-25T02:13:13.975187Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 4s 424us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.03415229325426044, 0.9901]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T00:21:44.714118Z",
     "start_time": "2018-01-25T00:17:23.314110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "lambda_3 (Lambda)            (None, 14, 14, 1)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 196)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 20)                3940      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 4,230\n",
      "Trainable params: 4,190\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 8s 163us/step - loss: 0.4470 - sparse_categorical_accuracy: 0.8688 - val_loss: 0.2546 - val_sparse_categorical_accuracy: 0.9245\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 7s 150us/step - loss: 0.2676 - sparse_categorical_accuracy: 0.9204 - val_loss: 0.2111 - val_sparse_categorical_accuracy: 0.9357\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 7s 151us/step - loss: 0.2261 - sparse_categorical_accuracy: 0.9312 - val_loss: 0.1785 - val_sparse_categorical_accuracy: 0.9463\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 9s 182us/step - loss: 0.2027 - sparse_categorical_accuracy: 0.9391 - val_loss: 0.1685 - val_sparse_categorical_accuracy: 0.9502\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 7s 153us/step - loss: 0.1920 - sparse_categorical_accuracy: 0.9403 - val_loss: 0.1646 - val_sparse_categorical_accuracy: 0.9517\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 8s 162us/step - loss: 0.1803 - sparse_categorical_accuracy: 0.9447 - val_loss: 0.1796 - val_sparse_categorical_accuracy: 0.9448\n",
      "Epoch 7/100\n",
      "48000/48000 [==============================] - 8s 165us/step - loss: 0.1765 - sparse_categorical_accuracy: 0.9455 - val_loss: 0.1601 - val_sparse_categorical_accuracy: 0.9517\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 8s 162us/step - loss: 0.1733 - sparse_categorical_accuracy: 0.9475 - val_loss: 0.1586 - val_sparse_categorical_accuracy: 0.9515\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 8s 175us/step - loss: 0.1688 - sparse_categorical_accuracy: 0.9476 - val_loss: 0.1568 - val_sparse_categorical_accuracy: 0.9527\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 8s 164us/step - loss: 0.1635 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.1548 - val_sparse_categorical_accuracy: 0.9551\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 8s 159us/step - loss: 0.1616 - sparse_categorical_accuracy: 0.9487 - val_loss: 0.1536 - val_sparse_categorical_accuracy: 0.9537\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 0.1564 - sparse_categorical_accuracy: 0.9516 - val_loss: 0.1526 - val_sparse_categorical_accuracy: 0.9543\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 9s 184us/step - loss: 0.1560 - sparse_categorical_accuracy: 0.9517 - val_loss: 0.1545 - val_sparse_categorical_accuracy: 0.9533\n",
      "Epoch 14/100\n",
      "48000/48000 [==============================] - 9s 180us/step - loss: 0.1543 - sparse_categorical_accuracy: 0.9522 - val_loss: 0.1501 - val_sparse_categorical_accuracy: 0.9565\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 9s 181us/step - loss: 0.1518 - sparse_categorical_accuracy: 0.9527 - val_loss: 0.1523 - val_sparse_categorical_accuracy: 0.9535\n",
      "Epoch 16/100\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.1514 - sparse_categorical_accuracy: 0.9538\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "48000/48000 [==============================] - 8s 174us/step - loss: 0.1513 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.1501 - val_sparse_categorical_accuracy: 0.9549\n",
      "Epoch 17/100\n",
      "48000/48000 [==============================] - 8s 170us/step - loss: 0.1366 - sparse_categorical_accuracy: 0.9580 - val_loss: 0.1377 - val_sparse_categorical_accuracy: 0.9597\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 8s 168us/step - loss: 0.1338 - sparse_categorical_accuracy: 0.9585 - val_loss: 0.1356 - val_sparse_categorical_accuracy: 0.9603\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 8s 172us/step - loss: 0.1318 - sparse_categorical_accuracy: 0.9584 - val_loss: 0.1360 - val_sparse_categorical_accuracy: 0.9603\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 8s 161us/step - loss: 0.1303 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.1353 - val_sparse_categorical_accuracy: 0.9603\n",
      "Epoch 21/100\n",
      "48000/48000 [==============================] - 8s 164us/step - loss: 0.1296 - sparse_categorical_accuracy: 0.9591 - val_loss: 0.1355 - val_sparse_categorical_accuracy: 0.9603\n",
      "Epoch 22/100\n",
      "47968/48000 [============================>.] - ETA: 0s - loss: 0.1308 - sparse_categorical_accuracy: 0.9601\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "48000/48000 [==============================] - 8s 160us/step - loss: 0.1308 - sparse_categorical_accuracy: 0.9601 - val_loss: 0.1361 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 23/100\n",
      "48000/48000 [==============================] - 8s 167us/step - loss: 0.1291 - sparse_categorical_accuracy: 0.9600 - val_loss: 0.1351 - val_sparse_categorical_accuracy: 0.9603\n",
      "Epoch 24/100\n",
      "48000/48000 [==============================] - 8s 159us/step - loss: 0.1264 - sparse_categorical_accuracy: 0.9606 - val_loss: 0.1349 - val_sparse_categorical_accuracy: 0.9603\n",
      "Epoch 25/100\n",
      "48000/48000 [==============================] - 7s 156us/step - loss: 0.1290 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.1350 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 26/100\n",
      "47712/48000 [============================>.] - ETA: 0s - loss: 0.1290 - sparse_categorical_accuracy: 0.9598\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
      "48000/48000 [==============================] - 7s 155us/step - loss: 0.1290 - sparse_categorical_accuracy: 0.9599 - val_loss: 0.1351 - val_sparse_categorical_accuracy: 0.9603\n",
      "Epoch 27/100\n",
      "48000/48000 [==============================] - 7s 150us/step - loss: 0.1275 - sparse_categorical_accuracy: 0.9598 - val_loss: 0.1346 - val_sparse_categorical_accuracy: 0.9606\n",
      "Epoch 28/100\n",
      "48000/48000 [==============================] - 8s 166us/step - loss: 0.1279 - sparse_categorical_accuracy: 0.9596 - val_loss: 0.1352 - val_sparse_categorical_accuracy: 0.9605\n",
      "Epoch 29/100\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.1288 - sparse_categorical_accuracy: 0.9591\n",
      "Epoch 00029: ReduceLROnPlateau reducing learning rate to 2.000000222324161e-07.\n",
      "48000/48000 [==============================] - 8s 159us/step - loss: 0.1286 - sparse_categorical_accuracy: 0.9592 - val_loss: 0.1346 - val_sparse_categorical_accuracy: 0.9606\n",
      "Epoch 30/100\n",
      "47808/48000 [============================>.] - ETA: 0s - loss: 0.1275 - sparse_categorical_accuracy: 0.9600\n",
      "Epoch 00030: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-08.\n",
      "48000/48000 [==============================] - 8s 157us/step - loss: 0.1276 - sparse_categorical_accuracy: 0.9600 - val_loss: 0.1353 - val_sparse_categorical_accuracy: 0.9604\n",
      "Epoch 31/100\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.1257 - sparse_categorical_accuracy: 0.9601\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-09.\n",
      "48000/48000 [==============================] - 8s 164us/step - loss: 0.1257 - sparse_categorical_accuracy: 0.9601 - val_loss: 0.1351 - val_sparse_categorical_accuracy: 0.9607\n",
      "Epoch 32/100\n",
      "47968/48000 [============================>.] - ETA: 0s - loss: 0.1255 - sparse_categorical_accuracy: 0.9614\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-10.\n",
      "48000/48000 [==============================] - 8s 158us/step - loss: 0.1255 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.1349 - val_sparse_categorical_accuracy: 0.9603\n",
      "Epoch 33/100\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.1268 - sparse_categorical_accuracy: 0.9600\n",
      "Epoch 00033: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-11.\n",
      "48000/48000 [==============================] - 7s 136us/step - loss: 0.1269 - sparse_categorical_accuracy: 0.9600 - val_loss: 0.1350 - val_sparse_categorical_accuracy: 0.9607\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12b1858d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_t = K.constant((14,14), dtype=\"int32\")\n",
    "def resize(x):\n",
    "    \n",
    "    return tf.image.resize_images(x, size=size_t)\n",
    "\n",
    "fc_model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Lambda(resize),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(20, activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(np.max(y_train) + 1, activation=\"softmax\")\n",
    "])\n",
    "fc_model.summary()\n",
    "fc_model.compile(\n",
    "    \"nadam\",\n",
    "    \"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"])\n",
    "fc_model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_split=.2,\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            factor=0.1,\n",
    "            patience=1,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(patience=6)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T00:08:18.079220Z",
     "start_time": "2018-01-25T00:03:40.613153Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 7, 1)           0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 49)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 20)                1000      \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 1,290\n",
      "Trainable params: 1,250\n",
      "Non-trainable params: 40\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/100\n",
      "48000/48000 [==============================] - 9s 195us/step - loss: 0.7083 - sparse_categorical_accuracy: 0.7769 - val_loss: 0.4594 - val_sparse_categorical_accuracy: 0.8546\n",
      "Epoch 2/100\n",
      "48000/48000 [==============================] - 8s 164us/step - loss: 0.5009 - sparse_categorical_accuracy: 0.8367 - val_loss: 0.4282 - val_sparse_categorical_accuracy: 0.8617\n",
      "Epoch 3/100\n",
      "48000/48000 [==============================] - 8s 161us/step - loss: 0.4673 - sparse_categorical_accuracy: 0.8472 - val_loss: 0.3985 - val_sparse_categorical_accuracy: 0.8709\n",
      "Epoch 4/100\n",
      "48000/48000 [==============================] - 8s 167us/step - loss: 0.4510 - sparse_categorical_accuracy: 0.8540 - val_loss: 0.4078 - val_sparse_categorical_accuracy: 0.8678\n",
      "Epoch 5/100\n",
      "48000/48000 [==============================] - 9s 190us/step - loss: 0.4399 - sparse_categorical_accuracy: 0.8568 - val_loss: 0.3753 - val_sparse_categorical_accuracy: 0.8775\n",
      "Epoch 6/100\n",
      "48000/48000 [==============================] - 10s 210us/step - loss: 0.4294 - sparse_categorical_accuracy: 0.8596 - val_loss: 0.3881 - val_sparse_categorical_accuracy: 0.8762\n",
      "Epoch 7/100\n",
      "47936/48000 [============================>.] - ETA: 0s - loss: 0.4220 - sparse_categorical_accuracy: 0.8623\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "48000/48000 [==============================] - 12s 249us/step - loss: 0.4219 - sparse_categorical_accuracy: 0.8624 - val_loss: 0.3854 - val_sparse_categorical_accuracy: 0.8738\n",
      "Epoch 8/100\n",
      "48000/48000 [==============================] - 11s 235us/step - loss: 0.4099 - sparse_categorical_accuracy: 0.8668 - val_loss: 0.3573 - val_sparse_categorical_accuracy: 0.8869\n",
      "Epoch 9/100\n",
      "48000/48000 [==============================] - 10s 218us/step - loss: 0.4044 - sparse_categorical_accuracy: 0.8679 - val_loss: 0.3568 - val_sparse_categorical_accuracy: 0.8848\n",
      "Epoch 10/100\n",
      "48000/48000 [==============================] - 11s 225us/step - loss: 0.4019 - sparse_categorical_accuracy: 0.8699 - val_loss: 0.3563 - val_sparse_categorical_accuracy: 0.8847\n",
      "Epoch 11/100\n",
      "48000/48000 [==============================] - 11s 224us/step - loss: 0.4014 - sparse_categorical_accuracy: 0.8691 - val_loss: 0.3556 - val_sparse_categorical_accuracy: 0.8852\n",
      "Epoch 12/100\n",
      "48000/48000 [==============================] - 11s 220us/step - loss: 0.4020 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.3549 - val_sparse_categorical_accuracy: 0.8872\n",
      "Epoch 13/100\n",
      "48000/48000 [==============================] - 11s 230us/step - loss: 0.3992 - sparse_categorical_accuracy: 0.8704 - val_loss: 0.3549 - val_sparse_categorical_accuracy: 0.8857\n",
      "Epoch 14/100\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.4003 - sparse_categorical_accuracy: 0.8684\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 2.0000000949949027e-05.\n",
      "48000/48000 [==============================] - 12s 244us/step - loss: 0.4000 - sparse_categorical_accuracy: 0.8685 - val_loss: 0.3556 - val_sparse_categorical_accuracy: 0.8868\n",
      "Epoch 15/100\n",
      "48000/48000 [==============================] - 11s 233us/step - loss: 0.4004 - sparse_categorical_accuracy: 0.8701 - val_loss: 0.3539 - val_sparse_categorical_accuracy: 0.8870\n",
      "Epoch 16/100\n",
      "48000/48000 [==============================] - 11s 223us/step - loss: 0.3976 - sparse_categorical_accuracy: 0.8695 - val_loss: 0.3539 - val_sparse_categorical_accuracy: 0.8870\n",
      "Epoch 17/100\n",
      "47968/48000 [============================>.] - ETA: 0s - loss: 0.3995 - sparse_categorical_accuracy: 0.8696\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 2.0000001313746906e-06.\n",
      "48000/48000 [==============================] - 11s 225us/step - loss: 0.3994 - sparse_categorical_accuracy: 0.8696 - val_loss: 0.3539 - val_sparse_categorical_accuracy: 0.8875\n",
      "Epoch 18/100\n",
      "48000/48000 [==============================] - 11s 225us/step - loss: 0.3982 - sparse_categorical_accuracy: 0.8690 - val_loss: 0.3536 - val_sparse_categorical_accuracy: 0.8871\n",
      "Epoch 19/100\n",
      "48000/48000 [==============================] - 11s 229us/step - loss: 0.3961 - sparse_categorical_accuracy: 0.8702 - val_loss: 0.3534 - val_sparse_categorical_accuracy: 0.8868\n",
      "Epoch 20/100\n",
      "48000/48000 [==============================] - 11s 228us/step - loss: 0.3977 - sparse_categorical_accuracy: 0.8710 - val_loss: 0.3537 - val_sparse_categorical_accuracy: 0.8863\n",
      "Epoch 21/100\n",
      "47840/48000 [============================>.] - ETA: 0s - loss: 0.3976 - sparse_categorical_accuracy: 0.8702\n",
      "Epoch 00021: ReduceLROnPlateau reducing learning rate to 2.000000222324161e-07.\n",
      "48000/48000 [==============================] - 12s 244us/step - loss: 0.3974 - sparse_categorical_accuracy: 0.8703 - val_loss: 0.3534 - val_sparse_categorical_accuracy: 0.8878\n",
      "Epoch 22/100\n",
      "47744/48000 [============================>.] - ETA: 0s - loss: 0.3967 - sparse_categorical_accuracy: 0.8701\n",
      "Epoch 00022: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-08.\n",
      "48000/48000 [==============================] - 12s 246us/step - loss: 0.3969 - sparse_categorical_accuracy: 0.8702 - val_loss: 0.3538 - val_sparse_categorical_accuracy: 0.8868\n",
      "Epoch 23/100\n",
      "47904/48000 [============================>.] - ETA: 0s - loss: 0.3962 - sparse_categorical_accuracy: 0.8705\n",
      "Epoch 00023: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-09.\n",
      "48000/48000 [==============================] - 11s 232us/step - loss: 0.3966 - sparse_categorical_accuracy: 0.8703 - val_loss: 0.3534 - val_sparse_categorical_accuracy: 0.8878\n",
      "Epoch 24/100\n",
      "47776/48000 [============================>.] - ETA: 0s - loss: 0.3992 - sparse_categorical_accuracy: 0.8695\n",
      "Epoch 00024: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-10.\n",
      "48000/48000 [==============================] - 8s 173us/step - loss: 0.3991 - sparse_categorical_accuracy: 0.8696 - val_loss: 0.3535 - val_sparse_categorical_accuracy: 0.8881\n",
      "Epoch 25/100\n",
      "47872/48000 [============================>.] - ETA: 0s - loss: 0.3978 - sparse_categorical_accuracy: 0.8705\n",
      "Epoch 00025: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-11.\n",
      "48000/48000 [==============================] - 8s 176us/step - loss: 0.3978 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.3535 - val_sparse_categorical_accuracy: 0.8878\n",
      "Epoch 26/100\n",
      "47904/48000 [============================>.] - ETA: 0s - loss: 0.3971 - sparse_categorical_accuracy: 0.8707\n",
      "Epoch 00026: ReduceLROnPlateau reducing learning rate to 2.000000165480742e-12.\n",
      "48000/48000 [==============================] - 9s 198us/step - loss: 0.3971 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.3536 - val_sparse_categorical_accuracy: 0.8870\n",
      "Epoch 27/100\n",
      "47680/48000 [============================>.] - ETA: 0s - loss: 0.3953 - sparse_categorical_accuracy: 0.8707\n",
      "Epoch 00027: ReduceLROnPlateau reducing learning rate to 2.000000208848829e-13.\n",
      "48000/48000 [==============================] - 9s 181us/step - loss: 0.3952 - sparse_categorical_accuracy: 0.8706 - val_loss: 0.3538 - val_sparse_categorical_accuracy: 0.8872\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x12d64ffd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc_model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=x_train.shape[1:]),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPool2D(2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(20, activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(np.max(y_train) + 1, activation=\"softmax\")\n",
    "])\n",
    "fc_model.summary()\n",
    "fc_model.compile(\n",
    "    \"nadam\",\n",
    "    \"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"])\n",
    "fc_model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_split=.2,\n",
    "    epochs=100,\n",
    "    callbacks=[\n",
    "        keras.callbacks.ReduceLROnPlateau(\n",
    "            factor=0.1,\n",
    "            patience=1,\n",
    "            verbose=1\n",
    "        ),\n",
    "        keras.callbacks.EarlyStopping(patience=6)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T02:13:58.933765Z",
     "start_time": "2018-01-25T02:13:45.549958Z"
    }
   },
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "x_train = (x_train - np.mean(x_train, axis = (1,2), keepdims=True))/np.std(x_train, axis = (1,2), keepdims=True)\n",
    "x_test = (x_test - np.mean(x_test, axis = (1,2), keepdims=True))/np.std(x_test, axis = (1,2), keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T02:36:11.539691Z",
     "start_time": "2018-01-25T02:15:47.794024Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 32, 32, 10)        280       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 15, 15, 10)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 15, 15, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 15, 15, 15)        1365      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 7, 7, 15)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 7, 7, 15)          60        \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 7, 7, 20)          2720      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 3, 3, 20)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 3, 3, 20)          80        \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 180)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 20)                3620      \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 8,455\n",
      "Trainable params: 8,325\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 100s 2ms/step - loss: 1.5279 - sparse_categorical_accuracy: 0.4642 - val_loss: 1.2793 - val_sparse_categorical_accuracy: 0.5475\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 116s 3ms/step - loss: 1.2007 - sparse_categorical_accuracy: 0.5805 - val_loss: 1.1252 - val_sparse_categorical_accuracy: 0.6033\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 102s 3ms/step - loss: 1.0854 - sparse_categorical_accuracy: 0.6213 - val_loss: 1.1047 - val_sparse_categorical_accuracy: 0.6091\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 109s 3ms/step - loss: 1.0232 - sparse_categorical_accuracy: 0.6460 - val_loss: 1.0079 - val_sparse_categorical_accuracy: 0.6503\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 103s 3ms/step - loss: 0.9841 - sparse_categorical_accuracy: 0.6591 - val_loss: 0.9684 - val_sparse_categorical_accuracy: 0.6608\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 91s 2ms/step - loss: 0.9537 - sparse_categorical_accuracy: 0.6676 - val_loss: 0.9791 - val_sparse_categorical_accuracy: 0.6515\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 92s 2ms/step - loss: 0.9325 - sparse_categorical_accuracy: 0.6770 - val_loss: 0.9293 - val_sparse_categorical_accuracy: 0.6764\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 100s 2ms/step - loss: 0.9175 - sparse_categorical_accuracy: 0.6827 - val_loss: 0.9446 - val_sparse_categorical_accuracy: 0.6690\n",
      "Epoch 9/100\n",
      "39968/40000 [============================>.] - ETA: 0s - loss: 0.9005 - sparse_categorical_accuracy: 0.6877\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00020000000949949026.\n",
      "40000/40000 [==============================] - 85s 2ms/step - loss: 0.9004 - sparse_categorical_accuracy: 0.6879 - val_loss: 0.9377 - val_sparse_categorical_accuracy: 0.6681\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 85s 2ms/step - loss: 0.8278 - sparse_categorical_accuracy: 0.7160 - val_loss: 0.8773 - val_sparse_categorical_accuracy: 0.6921\n",
      "Epoch 11/100\n",
      "40000/40000 [==============================] - 93s 2ms/step - loss: 0.8152 - sparse_categorical_accuracy: 0.7171 - val_loss: 0.8727 - val_sparse_categorical_accuracy: 0.6937\n",
      "Epoch 12/100\n",
      "40000/40000 [==============================] - 93s 2ms/step - loss: 0.8070 - sparse_categorical_accuracy: 0.7222 - val_loss: 0.8726 - val_sparse_categorical_accuracy: 0.6953\n",
      "Epoch 13/100\n",
      "19200/40000 [=============>................] - ETA: 54s - loss: 0.8034 - sparse_categorical_accuracy: 0.7206"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-ce9f8cb0a4f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     metrics=[\"sparse_categorical_accuracy\"])\n\u001b[1;32m     26\u001b[0m fc_model.fit(\n\u001b[0;32m---> 27\u001b[0;31m     x=x_train, y=y_train, validation_split=.2, epochs=100, callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fc_model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=x_train.shape[1:]),\n",
    "    \n",
    "    keras.layers.Conv2D(10,5,activation=\"elu\", padding=\"same\"),\n",
    "    keras.layers.MaxPool2D(3,2, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(15,4,activation=\"elu\", padding=\"same\"),\n",
    "    keras.layers.MaxPool2D(3,2, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(20,3,activation=\"elu\", padding=\"same\"),\n",
    "    keras.layers.MaxPool2D(3,2, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(20, activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(np.max(y_train) + 1, activation=\"softmax\")\n",
    "])\n",
    "fc_model.summary()\n",
    "fc_model.compile(\n",
    "    \"nadam\",\n",
    "    \"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"])\n",
    "fc_model.fit(\n",
    "    x=x_train, y=y_train, validation_split=.2, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T02:42:04.424433Z",
     "start_time": "2018-01-25T02:42:04.406559Z"
    }
   },
   "outputs": [],
   "source": [
    "def flip(x):\n",
    "    return tf.map_fn(lambda img: tf.image.random_flip_left_right(img), x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T02:54:56.460114Z",
     "start_time": "2018-01-25T02:42:05.240807Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_11 (InputLayer)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "lambda_5 (Lambda)            (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 32, 32, 10)        760       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling (None, 16, 16, 10)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 16, 16, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 16, 16, 15)        2415      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 8, 8, 15)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_26 (Batc (None, 8, 8, 15)          60        \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 20)          2720      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 4, 4, 20)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_27 (Batc (None, 4, 4, 20)          80        \n",
      "_________________________________________________________________\n",
      "flatten_11 (Flatten)         (None, 320)               0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 20)                6420      \n",
      "_________________________________________________________________\n",
      "batch_normalization_28 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 12,785\n",
      "Trainable params: 12,655\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n",
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 147s 4ms/step - loss: 1.3990 - sparse_categorical_accuracy: 0.5095 - val_loss: 1.1783 - val_sparse_categorical_accuracy: 0.5825\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 151s 4ms/step - loss: 1.1193 - sparse_categorical_accuracy: 0.6105 - val_loss: 1.0245 - val_sparse_categorical_accuracy: 0.6439\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 169s 4ms/step - loss: 1.0308 - sparse_categorical_accuracy: 0.6417 - val_loss: 0.9780 - val_sparse_categorical_accuracy: 0.6580\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 172s 4ms/step - loss: 0.9712 - sparse_categorical_accuracy: 0.6621 - val_loss: 0.9642 - val_sparse_categorical_accuracy: 0.6678\n",
      "Epoch 5/100\n",
      "33856/40000 [========================>.....] - ETA: 22s - loss: 0.9429 - sparse_categorical_accuracy: 0.6745"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-b859bb93656e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     metrics=[\"sparse_categorical_accuracy\"])\n\u001b[1;32m     27\u001b[0m fc_model.fit(\n\u001b[0;32m---> 28\u001b[0;31m     x=x_train, y=y_train, validation_split=.2, epochs=100, callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fc_model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Lambda(flip),\n",
    "    \n",
    "    keras.layers.Conv2D(10,5,activation=\"elu\", padding=\"same\"),\n",
    "    keras.layers.MaxPool2D(3,2, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(15,4,activation=\"elu\", padding=\"same\"),\n",
    "    keras.layers.MaxPool2D(3,2, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(20,3,activation=\"elu\", padding=\"same\"),\n",
    "    keras.layers.MaxPool2D(3,2, padding=\"same\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(20, activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(np.max(y_train) + 1, activation=\"softmax\")\n",
    "])\n",
    "fc_model.summary()\n",
    "fc_model.compile(\n",
    "    \"nadam\",\n",
    "    \"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"])\n",
    "fc_model.fit(\n",
    "    x=x_train, y=y_train, validation_split=.2, epochs=100, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T02:57:21.529257Z",
     "start_time": "2018-01-25T02:57:21.515790Z"
    }
   },
   "outputs": [],
   "source": [
    "def frac_pool(x):\n",
    "    out, _, _ = tf.nn.fractional_max_pool(\n",
    "        x,\n",
    "        [1.0, 1.4, 1.4, 1.0],\n",
    "        overlapping=True,\n",
    "    )\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T02:58:43.152205Z",
     "start_time": "2018-01-25T02:58:41.077367Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_16 (InputLayer)        (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "lambda_19 (Lambda)           (None, 32, 32, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 32, 32, 10)        760       \n",
      "_________________________________________________________________\n",
      "lambda_20 (Lambda)           (None, 22, 22, 10)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_46 (Batc (None, 22, 22, 10)        40        \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 22, 22, 20)        3220      \n",
      "_________________________________________________________________\n",
      "lambda_21 (Lambda)           (None, 15, 15, 20)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_47 (Batc (None, 15, 15, 20)        80        \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 15, 15, 30)        5430      \n",
      "_________________________________________________________________\n",
      "lambda_22 (Lambda)           (None, 10, 10, 30)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_48 (Batc (None, 10, 10, 30)        120       \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 10, 10, 40)        10840     \n",
      "_________________________________________________________________\n",
      "lambda_23 (Lambda)           (None, 7, 7, 40)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_49 (Batc (None, 7, 7, 40)          160       \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 7, 7, 30)          10830     \n",
      "_________________________________________________________________\n",
      "lambda_24 (Lambda)           (None, 5, 5, 30)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 5, 5, 30)          120       \n",
      "_________________________________________________________________\n",
      "flatten_16 (Flatten)         (None, 750)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 20)                15020     \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 20)                80        \n",
      "_________________________________________________________________\n",
      "dense_32 (Dense)             (None, 10)                210       \n",
      "=================================================================\n",
      "Total params: 46,910\n",
      "Trainable params: 46,610\n",
      "Non-trainable params: 300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "fc_model = keras.Sequential([\n",
    "    keras.layers.InputLayer(input_shape=x_train.shape[1:]),\n",
    "    keras.layers.Lambda(flip),\n",
    "    \n",
    "    keras.layers.Conv2D(10,5,activation=\"elu\", padding=\"same\"),\n",
    "    keras.layers.Lambda(frac_pool),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(20,4,activation=\"elu\", padding=\"same\"),\n",
    "    keras.layers.Lambda(frac_pool),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(30,3,activation=\"elu\", padding=\"same\"),\n",
    "    keras.layers.Lambda(frac_pool),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(40,3,activation=\"elu\", padding=\"same\"),\n",
    "    keras.layers.Lambda(frac_pool),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Conv2D(50,3,activation=\"elu\", padding=\"same\"),\n",
    "    keras.layers.Lambda(frac_pool),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    \n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(20, activation=\"elu\"),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(np.max(y_train) + 1, activation=\"softmax\")\n",
    "])\n",
    "fc_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-25T04:07:09.613364Z",
     "start_time": "2018-01-25T02:58:57.923254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "40000/40000 [==============================] - 294s 7ms/step - loss: 1.5485 - sparse_categorical_accuracy: 0.4523 - val_loss: 1.4004 - val_sparse_categorical_accuracy: 0.5045\n",
      "Epoch 2/100\n",
      "40000/40000 [==============================] - 289s 7ms/step - loss: 1.2476 - sparse_categorical_accuracy: 0.5631 - val_loss: 1.2520 - val_sparse_categorical_accuracy: 0.5686\n",
      "Epoch 3/100\n",
      "40000/40000 [==============================] - 295s 7ms/step - loss: 1.1447 - sparse_categorical_accuracy: 0.6012 - val_loss: 1.1834 - val_sparse_categorical_accuracy: 0.5891\n",
      "Epoch 4/100\n",
      "40000/40000 [==============================] - 262s 7ms/step - loss: 1.0804 - sparse_categorical_accuracy: 0.6230 - val_loss: 1.0754 - val_sparse_categorical_accuracy: 0.6262\n",
      "Epoch 5/100\n",
      "40000/40000 [==============================] - 286s 7ms/step - loss: 1.0291 - sparse_categorical_accuracy: 0.6416 - val_loss: 1.0626 - val_sparse_categorical_accuracy: 0.6301\n",
      "Epoch 6/100\n",
      "40000/40000 [==============================] - 266s 7ms/step - loss: 0.9922 - sparse_categorical_accuracy: 0.6542 - val_loss: 1.0179 - val_sparse_categorical_accuracy: 0.6446\n",
      "Epoch 7/100\n",
      "40000/40000 [==============================] - 265s 7ms/step - loss: 0.9638 - sparse_categorical_accuracy: 0.6650 - val_loss: 0.9482 - val_sparse_categorical_accuracy: 0.6684\n",
      "Epoch 8/100\n",
      "40000/40000 [==============================] - 248s 6ms/step - loss: 0.9392 - sparse_categorical_accuracy: 0.6729 - val_loss: 0.9635 - val_sparse_categorical_accuracy: 0.6597\n",
      "Epoch 9/100\n",
      "40000/40000 [==============================] - 244s 6ms/step - loss: 0.9138 - sparse_categorical_accuracy: 0.6826 - val_loss: 0.9088 - val_sparse_categorical_accuracy: 0.6841\n",
      "Epoch 10/100\n",
      "40000/40000 [==============================] - 1541s 39ms/step - loss: 0.8911 - sparse_categorical_accuracy: 0.6911 - val_loss: 0.9771 - val_sparse_categorical_accuracy: 0.6623\n",
      "Epoch 11/100\n",
      "10048/40000 [======>.......................] - ETA: 4:40 - loss: 0.8721 - sparse_categorical_accuracy: 0.6983"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-ed515351a9ec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     metrics=[\"sparse_categorical_accuracy\"])\n\u001b[1;32m      5\u001b[0m fc_model.fit(\n\u001b[0;32m----> 6\u001b[0;31m     x=x_train, y=y_train, validation_split=.2, epochs=100, callbacks=callbacks)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    963\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fc_model.compile(\n",
    "    \"nadam\",\n",
    "    \"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"])\n",
    "fc_model.fit(\n",
    "    x=x_train, y=y_train, validation_split=.2, epochs=100, callbacks=callbacks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
